{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# YOLOv8目标检测使用范例——风机识别"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8a6bb239e632664"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "from osgeo import gdal\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import yaml\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from shapely import Polygon, MultiPolygon\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "sys.path.append('../../ultralytics/dataset_preparation')\n",
    "sys.path.append('../../ultralytics/inference/utils')\n",
    "import yolo_dataset_utils\n",
    "import split_image_v1\n",
    "import split_image_v2\n",
    "import yolov8_seg_handle\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.gif', '.webp')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T03:20:22.460629600Z",
     "start_time": "2024-01-09T03:20:19.997252600Z"
    }
   },
   "id": "bfb44cc9ef29bc04"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dfcc5b45ca9452ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.数据处理\n",
    "### 下载标注数据集\n",
    "#### 数据集格式如下：\n",
    "风机数据\n",
    "____风机1\n",
    "____风机2\n",
    "________标注内容\n",
    "____________图片1标注.shp\n",
    "____________图片2标注.shp\n",
    "________图片1.tif\n",
    "________图片2.tif\n",
    "____风机3\n",
    "...\n",
    "\n",
    "其中，风机1、2等代表标注的点，里面的图片代表每个点的标注期\n",
    "\n",
    "运行以下代码下载数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "108b95b5815e5883"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download&confirm=1\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params={\"id\": id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {\"id\": id, \"confirm\": token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, destination)\n",
    "\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith(\"download_warning\"):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"wind_turbine.zip\"\n",
    "extract_path = \"./wind_turbine/风机数据\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    for file_info in zip_ref.infolist():\n",
    "        file_name = file_info.filename\n",
    "\n",
    "        # Attempt to decode the file name\n",
    "        try:\n",
    "            file_name = file_name.encode('cp437').decode('gbk')  # Adjust the encoding as needed\n",
    "        except:\n",
    "            file_name = file_name.encode('cp437').decode('utf-8', 'ignore')  # Fallback to UTF-8\n",
    "\n",
    "        extracted_path = os.path.join(extract_path, file_name)\n",
    "        \n",
    "        # Create directory structure\n",
    "        if file_info.is_dir():\n",
    "            os.makedirs(extracted_path, exist_ok=True)\n",
    "        else:\n",
    "            os.makedirs(os.path.dirname(extracted_path), exist_ok=True)\n",
    "            \n",
    "            # Extract and write the file\n",
    "            with open(extracted_path, 'wb') as f:\n",
    "                f.write(zip_ref.read(file_info.filename))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a0a8939168fc148"
  },
  {
   "cell_type": "markdown",
   "source": [
    "运行这个脚本，将数据集转化为yolo格式的训练集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f619dcc0533eba6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = 'wind_turbine'\n",
    "# 先将标注转成geojson\n",
    "yolo_dataset_utils.batch_convert_shapely(data_path)\n",
    "# 而后按照类别生成yolo格式标注\n",
    "yolo_dataset_utils.wind_turbine_geojson_classify(data_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dae633ac5db5e219"
  },
  {
   "cell_type": "markdown",
   "source": [
    "现在，wind_turbine/wind_turbine里面就是我们要的风机数据集。包括tif格式的图片和对应的txt格式文件。目前txt文件为矩形框，后面要转成锚框\n",
    "\n",
    "运行以下代码，划分训练集、测试集与验证集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdb10a0b11977664"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_path = 'wind_turbine/wind_turbine/images'\n",
    "txt_path = 'wind_turbine/wind_turbine/label_txt'\n",
    "# 运行以下脚本，划分训练集、验证集和测试集\n",
    "yolo_dataset_utils.split_train_val_test(img_path, txt_path, val_percentage=0.1, test_percentage=0.1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85f83af9275550fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "运行以下代码，将大图按照一定比例分割成小图"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb3508cb73a4c8ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 分别进入train, val, test目录下，运行分割图的脚本。运行后手动删除除了images和txt_bbox的其余文件夹。将txt_bbox重命名为labels\n",
    "split_sizes = [[700, 700], [900, 900], [1100, 1100]] # 此处数字代表像素点大小\n",
    "img_path = \"wind_turbine/wind_turbine/train/training_img\"\n",
    "label_path = \"wind_turbine/wind_turbine/train/training_label\"\n",
    "# split_image_v1为平切算法，即切割图片无重叠\n",
    "# split_image_v1(img_path, split_sizes, label_path, with_edge=False) # with_edge: 是否保留在边缘的目标\n",
    "# split_image_v2为有重叠切法，即切割图片之前有重叠部分\n",
    "split_image_v2.split_images_segment_v2(img_path, split_sizes, label_path, with_edge=False) # with_edge: 是否保留在边缘的目标\n",
    "\n",
    "# 运行以下代码，将分割格式label转化成目标检测的锚框\n",
    "segment_label_path = \"wind_turbine/wind_turbine/train/labels\"\n",
    "yolo_dataset_utils.txt2yolo_bbox(segment_label_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3db9a8fa35986389"
  },
  {
   "cell_type": "markdown",
   "source": [
    "运行以下代码，打印出图片看看标注是否正确。确定正确后删除out文件夹"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36a1232e0aeb8681"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_path = \"wind_turbine/wind_turbine/train/images\"\n",
    "label_path = \"wind_turbine/wind_turbine/train/labels\"\n",
    "yolo_dataset_utils.show_batch_image_bbox(img_path, label_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b3cc03757683b7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "至此，数据集准备工作完毕。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db1118c5560543a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.模型训练\n",
    "模型训练通过命令行执行。需要配置一个.yaml文件，说明数据集的位置。yaml文件范例见ultralytics/training/config\n",
    "\n",
    "运行如下代码下载预训练模型到本地\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45361cfe4dbb1399"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 运行如下代码下载预训练模型到本地\n",
    "def download_file(url, filename):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open the file in write-binary mode and write the contents\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully: {filename}\")\n",
    "    else:\n",
    "        print(\"Failed to download file\")\n",
    "\n",
    "# Example usage\n",
    "url = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt\"  # Replace with the actual URL\n",
    "filename = \"../../ultralytics/training/pre_models/yolov8x.pt\"      # Replace with your desired file name\n",
    "download_file(url, filename)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "384856a6c1b2a4c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "config配置完成后，在命令行运行如下代码开启训练过程：\n",
    "*yolo task=detect mode=train project=wind_turbine name=wind_turbine model=ultralytics/training/pre_models/yolov8x.pt data=ultralytics/training/config/wind_turbine.yaml  batch=16  epochs=401  device=0  patience=50  save_period=50 degrees=45 flipud=0.5 fliplr=0.5*\n",
    "\n",
    "其中，degrees，flipud和fliplr为数据增强的参数。更多参数详见官网：[https://docs.ultralytics.com/usage/cfg/#export](https://docs.ultralytics.com/usage/cfg/#export)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "506761c3368a7f83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.模型预测\n",
    "模型预测代码示例如下："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7470e1802b596442"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:开始切割图片\n",
      "INFO:root:切割图片完成!!!\n",
      "INFO:root:开始模型预测\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "0: 640x640 1 wind turbine, 1: 640x640 (no detections), 2: 640x640 1 wind turbine, 3: 640x640 (no detections), 4: 640x640 1 wind turbine, 5: 640x640 (no detections), 6: 640x640 1 wind turbine, 7: 640x640 1 wind turbine, 8: 640x640 (no detections), 9: 640x640 1 wind turbine, 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 1 wind turbine, 15: 640x640 1 wind turbine, 333.7ms\n",
      "Speed: 2.3ms preprocess, 20.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  7%|▋         | 1/14 [00:01<00:15,  1.19s/it]\n",
      "0: 640x640 1 wind turbine, 1: 640x640 1 wind turbine, 2: 640x640 1 wind turbine, 3: 640x640 1 wind turbine, 4: 640x640 2 wind turbines, 5: 640x640 1 wind turbine, 6: 640x640 1 wind turbine, 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 1 wind turbine, 15: 640x640 1 wind turbine, 269.8ms\n",
      "Speed: 2.2ms preprocess, 16.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 14%|█▍        | 2/14 [00:01<00:08,  1.45it/s]\n",
      "0: 640x640 1 wind turbine, 1: 640x640 1 wind turbine, 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 1 wind turbine, 13: 640x640 1 wind turbine, 14: 640x640 1 wind turbine, 15: 640x640 2 wind turbines, 267.9ms\n",
      "Speed: 2.2ms preprocess, 16.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 21%|██▏       | 3/14 [00:01<00:05,  1.90it/s]\n",
      "0: 640x640 (no detections), 1: 640x640 1 wind turbine, 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 1 wind turbine, 13: 640x640 (no detections), 14: 640x640 1 wind turbine, 15: 640x640 (no detections), 268.6ms\n",
      "Speed: 2.2ms preprocess, 16.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 29%|██▊       | 4/14 [00:02<00:04,  2.23it/s]\n",
      "0: 640x640 (no detections), 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 1 wind turbine, 7: 640x640 2 wind turbines, 8: 640x640 1 wind turbine, 9: 640x640 1 wind turbine, 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 (no detections), 15: 640x640 (no detections), 270.4ms\n",
      "Speed: 2.3ms preprocess, 16.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 36%|███▌      | 5/14 [00:02<00:03,  2.45it/s]\n",
      "0: 640x640 (no detections), 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 2 wind turbines, 5: 640x640 1 wind turbine, 6: 640x640 1 wind turbine, 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 (no detections), 15: 640x640 (no detections), 269.9ms\n",
      "Speed: 2.1ms preprocess, 16.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 43%|████▎     | 6/14 [00:02<00:03,  2.63it/s]\n",
      "0: 640x640 (no detections), 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 1 wind turbine, 10: 640x640 1 wind turbine, 11: 640x640 2 wind turbines, 12: 640x640 1 wind turbine, 13: 640x640 2 wind turbines, 14: 640x640 2 wind turbines, 15: 640x640 1 wind turbine, 269.4ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 50%|█████     | 7/14 [00:03<00:02,  2.74it/s]\n",
      "0: 640x640 1 wind turbine, 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 1 wind turbine, 7: 640x640 1 wind turbine, 8: 640x640 1 wind turbine, 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 (no detections), 15: 640x640 2 wind turbines, 270.5ms\n",
      "Speed: 2.2ms preprocess, 16.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 57%|█████▋    | 8/14 [00:03<00:02,  2.81it/s]\n",
      "0: 640x640 2 wind turbines, 1: 640x640 2 wind turbines, 2: 640x640 2 wind turbines, 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 (no detections), 8: 640x640 1 wind turbine, 9: 640x640 1 wind turbine, 10: 640x640 (no detections), 11: 640x640 1 wind turbine, 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 (no detections), 15: 640x640 (no detections), 269.3ms\n",
      "Speed: 2.3ms preprocess, 16.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 64%|██████▍   | 9/14 [00:03<00:01,  2.84it/s]\n",
      "0: 640x640 (no detections), 1: 640x640 1 wind turbine, 2: 640x640 2 wind turbines, 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 (no detections), 15: 640x640 (no detections), 269.3ms\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 71%|███████▏  | 10/14 [00:04<00:01,  2.90it/s]\n",
      "0: 640x640 (no detections), 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 4 wind turbines, 6: 640x640 2 wind turbines, 7: 640x640 3 wind turbines, 8: 640x640 3 wind turbines, 9: 640x640 2 wind turbines, 10: 640x640 2 wind turbines, 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 (no detections), 15: 640x640 1 wind turbine, 269.1ms\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 79%|███████▊  | 11/14 [00:04<00:01,  2.90it/s]\n",
      "0: 640x640 1 wind turbine, 1: 640x640 1 wind turbine, 2: 640x640 1 wind turbine, 3: 640x640 1 wind turbine, 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 2 wind turbines, 10: 640x640 1 wind turbine, 11: 640x640 2 wind turbines, 12: 640x640 1 wind turbine, 13: 640x640 (no detections), 14: 640x640 1 wind turbine, 15: 640x640 (no detections), 270.2ms\n",
      "Speed: 2.3ms preprocess, 16.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 86%|████████▌ | 12/14 [00:04<00:00,  2.90it/s]\n",
      "0: 640x640 (no detections), 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 2 wind turbines, 4: 640x640 3 wind turbines, 5: 640x640 1 wind turbine, 6: 640x640 1 wind turbine, 7: 640x640 1 wind turbine, 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 1 wind turbine, 14: 640x640 (no detections), 15: 640x640 (no detections), 269.2ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 93%|█████████▎| 13/14 [00:05<00:00,  2.93it/s]\n",
      "0: 640x640 (no detections), 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 (no detections), 134.7ms\n",
      "Speed: 1.7ms preprocess, 19.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.60it/s]\n",
      "INFO:root:模型预测完成\n",
      "INFO:root:开始后处理\n",
      "100%|██████████| 371/371 [00:00<00:00, 17627.92it/s]\n",
      "INFO:root:后处理完成\n",
      "INFO:root:生成图片完成\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.gif', '.webp')\n",
    "\n",
    "# 读取预测用config文件\n",
    "def get_config():\n",
    "    config_path = \"D:/Code/gitcode/train_pipeline/ultralytics/inference/config/wind_turbine_config.yaml\"\n",
    "    config_file = open(config_path, 'r', encoding='utf-8')\n",
    "    file_info = config_file.read()\n",
    "    config_dict = yaml.safe_load(file_info)\n",
    "    return config_dict\n",
    "\n",
    "# 图片预处理，将大图按照一定比例切割成小图\n",
    "def pre_handle(config_dict):\n",
    "    image_path = config_dict['image_path']\n",
    "    split_arr = config_dict['split_arr']\n",
    "    coordinates = config_dict['coordinates']\n",
    "    pixel_arr = yolov8_seg_handle.lon_lat_to_pixel(image_path, coordinates)\n",
    "    mid_dict = {'pixel_arr': pixel_arr}  # 用于存储中间结果\n",
    "    # 图片切割\n",
    "    logging.info('开始切割图片')\n",
    "    split_images_dict = yolov8_seg_handle.split_image_large(image_path, split_arr, pixel_arr)\n",
    "    mid_dict['split_images_dict'] = split_images_dict\n",
    "    logging.info(\"切割图片完成!!!\")\n",
    "    return mid_dict\n",
    "\n",
    "# 预测后处理，按照比面积或者比置信度将重叠的锚框去重\n",
    "def after_handle_bbox(config_dict, mid_dict, method='area'):\n",
    "    import geopandas as gpd\n",
    "    logging.info('开始后处理')\n",
    "    predict_result = mid_dict['predict_result']\n",
    "    all_box_arr = predict_result['all_box_arr']\n",
    "    weight_arr = predict_result['weight_arr']\n",
    "    label_arr = predict_result['label_arr']\n",
    "\n",
    "    overlap_percent = config_dict['overlap_percent']\n",
    "\n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame({\n",
    "        'weight': weight_arr,\n",
    "        'label': label_arr,\n",
    "        'box': all_box_arr,\n",
    "        'geometry': [Polygon(p) for p in all_box_arr]\n",
    "    })\n",
    "\n",
    "    # Spatial self-join to find overlapping polygons\n",
    "    joined_gdf = gpd.sjoin(gdf, gdf, how='inner', predicate='intersects')\n",
    "    # print(joined_gdf.columns)\n",
    "    # Initialize a set to keep track of processed indices\n",
    "    processed_indices = set()\n",
    "\n",
    "    for idx, row in tqdm(joined_gdf.iterrows(), total=joined_gdf.shape[0]):\n",
    "        row1 = idx\n",
    "        row2 = row['index_right']\n",
    "\n",
    "        if row1 == row2 or row1 in processed_indices or row2 in processed_indices:\n",
    "            continue\n",
    "\n",
    "        poly1 = gdf.at[row1, 'geometry']\n",
    "        poly2 = gdf.at[row2, 'geometry']\n",
    "        area1 = poly1.area\n",
    "        area2 = poly2.area\n",
    "        over_area = poly1.intersection(poly2).area\n",
    "\n",
    "        if over_area / area1 >= overlap_percent or over_area / area2 >= overlap_percent:\n",
    "            # 取大的\n",
    "            if method == 'area':\n",
    "                if area1 >= area2:\n",
    "                    processed_indices.add(row2)\n",
    "                else:\n",
    "                    processed_indices.add(row1)\n",
    "            else:\n",
    "                if gdf['weight'].tolist()[row1] >= gdf['weight'].tolist()[row2]:\n",
    "                    processed_indices.add(row2)\n",
    "                else:\n",
    "                    processed_indices.add(row1)\n",
    "    # Remove processed (merged) polygons\n",
    "    gdf = gdf.drop(index=list(processed_indices))\n",
    "    # Reconstruct the result\n",
    "    mid_dict['res_result'] = {\n",
    "        'res_box': gdf['box'].tolist(),\n",
    "        # Add other necessary fields\n",
    "        'res_weight': gdf['weight'].tolist(),\n",
    "        'res_label': gdf['label'].tolist()\n",
    "    }\n",
    "    logging.info('后处理完成')\n",
    "\n",
    "    return mid_dict\n",
    "\n",
    "# 生成geojson文件\n",
    "def create_geojson(config_dict, mid_dict):\n",
    "    start_time = config_dict['start_time']\n",
    "    image_path = config_dict['image_path']\n",
    "    out_flag = config_dict['out_flag']\n",
    "    out_file_path = config_dict['out_file_path']\n",
    "    class_names = config_dict['class_dict']\n",
    "\n",
    "    res_result = mid_dict['res_result']\n",
    "    res_box = res_result['res_box']\n",
    "    res_weight = res_result['res_weight']\n",
    "    res_label = res_result['res_label']\n",
    "    if not out_flag:\n",
    "        return mid_dict\n",
    "    time_now = int(time.time())\n",
    "    image_name = image_path.split('/')[-1]\n",
    "    path = image_path.replace('/' + image_name, '')\n",
    "    suf = image_name.split('.')[1]\n",
    "    show_path = path + '/out/' + image_name.replace('.' + suf, '_predict.geojson')\n",
    "\n",
    "    gdal.AllRegister()\n",
    "    dataset = gdal.Open(image_path)\n",
    "    adfGeoTransform = dataset.GetGeoTransform()\n",
    "\n",
    "    res_dict = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"crs\": {\"type\": \"name\", \"properties\": {\"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\"}},\n",
    "        \"features\": []\n",
    "    }\n",
    "    date = image_name.split('.')[0][-8:]\n",
    "    for index in range(len(res_box)):\n",
    "        polygon = res_box[index]\n",
    "        label = res_label[index]\n",
    "        weight = res_weight[index]\n",
    "        name = class_names[label]\n",
    "        feature = {\"type\": \"Feature\",\n",
    "                   \"properties\": {\"Id\": 0, \"name\": name, \"date\": date, \"area\": 0.0, \"label\": label, \"result\": 1,\n",
    "                                  \"XMMC\": \"\", \"HYMC\": \"\", \"weight\": weight, \"bz\": 0},\n",
    "                   \"geometry\": {\"type\": \"Polygon\", \"coordinates\": []}}\n",
    "        coordinate = []\n",
    "        for xy in polygon:\n",
    "            location = [xy[0] * adfGeoTransform[1] + adfGeoTransform[0],\n",
    "                        xy[1] * adfGeoTransform[5] + adfGeoTransform[3]]\n",
    "            coordinate.append(location)\n",
    "        coordinate.append(coordinate[0])\n",
    "        feature['geometry']['coordinates'].append(coordinate)\n",
    "        res_dict['features'].append(feature)\n",
    "\n",
    "    end_time = time.time()\n",
    "    consume_time = end_time - start_time\n",
    "    res = str(res_dict).replace('\\'', '\"').replace('None', '\"None\"')\n",
    "    res_dict['consume_time'] = consume_time\n",
    "    mid_dict['res'] = res\n",
    "\n",
    "    # 输出json文件， 默认不输出\n",
    "    out_file = open(show_path, 'w', encoding='utf8')\n",
    "    out_file.write(res)\n",
    "    out_file.close()\n",
    "\n",
    "    logging.info('图片路径：' + image_path + ' 总耗时（单位s）：' + str(consume_time))\n",
    "\n",
    "    return mid_dict\n",
    "\n",
    "# 绘制锚框\n",
    "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "# 生成预测后的示意图\n",
    "def show_images(config_dict, mid_dict):\n",
    "    image_path = config_dict['image_path']\n",
    "    model_path = config_dict['model_path']\n",
    "    show_flag = config_dict['show_flag']\n",
    "    class_dict = config_dict['class_dict']\n",
    "    if not show_flag:\n",
    "        return 0\n",
    "    res_result = mid_dict['res_result']\n",
    "    res_box = res_result['res_box']\n",
    "    res_weight = res_result['res_weight']\n",
    "    res_label = res_result['res_label']\n",
    "\n",
    "    image_name = image_path.split('/')[-1]\n",
    "    model_name = model_path.split('/')[-1].split('.')[0]\n",
    "    path = image_path.replace('/' + image_name, '')\n",
    "    suf = image_name.split('.')[1]\n",
    "    show_path = path + '/out/' + image_name.replace('.' + suf, '_show')\n",
    "    # 大图打上标签\n",
    "    if not os.path.exists(show_path):  # 判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(show_path)\n",
    "    image_name = image_path.split('/')[-1]\n",
    "    suf = image_name.split('.')[1]\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "    except:\n",
    "        return 0\n",
    "    box_len = len(res_box)\n",
    "\n",
    "    # Start with the bounding boxes\n",
    "    img_bbox = img.copy()  # Create a copy of the original image for bounding boxes\n",
    "\n",
    "    for row in range(box_len):\n",
    "        arr = res_box[row]\n",
    "        label = class_dict[res_label[row]]\n",
    "        confidence = res_weight[row]\n",
    "        xyxy = [arr[0][0], arr[0][1], arr[2][0], arr[2][1]]\n",
    "\n",
    "        plot_one_box(xyxy, img_bbox, label=f'{label} {round(confidence, 2)}', color=(0, 0, 255), line_thickness=2)\n",
    "\n",
    "    cv2.imwrite(os.path.join(show_path, image_name.replace('.' + suf, \"_bbox\" + f'_{model_name}.' + suf)), img_bbox)\n",
    "\n",
    "    logger.info('生成图片完成')\n",
    "\n",
    "# 只预测一张图片\n",
    "def single_predict(image_path, config_dict):\n",
    "    config_dict['image_path'] = image_path\n",
    "    # 2，预处理\n",
    "    mid_dict = pre_handle(config_dict)\n",
    "    # 3，模型识别\n",
    "    mid_dict = yolov8_seg_handle.model_predict_bbox(config_dict, mid_dict)\n",
    "    # 4，后处理\n",
    "    mid_dict = after_handle_bbox(config_dict, mid_dict)\n",
    "\n",
    "    # 5，生成输出结果\n",
    "    mid_dict = create_geojson(config_dict, mid_dict)\n",
    "    # 6，输出图片\n",
    "    show_images(config_dict, mid_dict)\n",
    "\n",
    "# 预测多张图片\n",
    "def batch_predict(image_file_path, config_dict):\n",
    "    image_names = os.listdir(image_file_path)\n",
    "    for image_name in image_names:\n",
    "        if image_name.endswith(IMAGE_EXTENSIONS):\n",
    "            # if image_name != 'car20210205.tif':\n",
    "            #    continue\n",
    "            print('预测，', image_name)\n",
    "            image_path = image_file_path + '/' + image_name\n",
    "            single_predict(image_path, config_dict)\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    # 1，参数处理\n",
    "    config_dict = get_config()\n",
    "    image_path = \"D:/Code/gitcode/train_pipeline/examples/yolov8_wind_turbine/wind_turbine/wind_turbine/test/test_img/wind_turbine_fengji9_20220906.tif\"\n",
    "    coordinates = '[]' #'[[119.64718, 34.44381], [119.68986, 34.41249]]'\n",
    "    config_dict['out_flag'] = False\n",
    "    config_dict['start_time'] = start_time\n",
    "    config_dict['image_path'] = image_path\n",
    "    # config_dict['image_path'] = image_path\n",
    "    coordinates = json.loads(coordinates)\n",
    "    config_dict['coordinates'] = coordinates\n",
    "    single_predict(image_path, config_dict)\n",
    "\n",
    "    image_file_path = \"D:/Code/Datasets/wind_turbine/dataset20240103/wind_turbine_blade/test_img\"\n",
    "    # batch_predict(image_file_path, config_dict)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T03:46:06.055870400Z",
     "start_time": "2024-01-09T03:45:59.567682100Z"
    }
   },
   "id": "b380707db65a3bd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
